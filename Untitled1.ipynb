{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37125it [00:01, 22907.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(841, 512)\n",
      "(841,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Dataset=pd.DataFrame([{'id':1 , '2':100}]) #исходный pandas-dataframe , содержащий айди картинки и вектора к ним и\n",
    "                        #результат свайпа пользователя \n",
    "Dataset = pd.read_csv('insight_face_model/vecs2.csv')\n",
    "TargetData = pd.read_csv('likes.csv')\n",
    "DictData = {}\n",
    "for index, row in tqdm(Dataset.iterrows()):\n",
    "    vector = row.values[0:512]\n",
    "    name = row.values[512]\n",
    "    DictData[name] = vector\n",
    "\n",
    "    \n",
    "batch_size = 10\n",
    "\n",
    "#DictData={'id1':[1 , 2 , 3 , ..] , 'id2': [2 , 4 ,6 , ..]}\n",
    "#TargetData = {'id1' : '1' , 'id2': '2'}\n",
    "#DeliveredData == TargetData\n",
    "\n",
    "#print(Dataset.shape)\n",
    "#print(TargetData[\"image_name\"].iloc[10])\n",
    "#print(TargetData)\n",
    "\n",
    "def CalculateScore(clf):\n",
    "    clf\n",
    "    \n",
    " # Ломается на последнем элементе   \n",
    "\n",
    "list_vecs = [] # list для пролайканых людей\n",
    "list_likes = [] # list лайк-дизлайк\n",
    "for i in range(TargetData.shape[0]): # посмотреть первые 800?\n",
    "    if TargetData[\"image_name\"].iloc[i] in DictData:\n",
    "        list_vecs.append(DictData[TargetData[\"image_name\"].iloc[i]])\n",
    "        list_likes.append(TargetData[\"target\"].iloc[i])\n",
    "print(np.array(list_vecs).shape)\n",
    "print(np.array(list_likes).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ServerUser:\n",
    "    def __init__(self , data):\n",
    "        self.data = pd.DataFrame()\n",
    "        self.UsedGirls = {}\n",
    "        self.innerVector = [] #Если будем все-таки делать через статистики\n",
    "        self.clf = SVC(kernel='linear' , C = 100 , random_state = 241)#Потестить  svm кросс-валидацие\n",
    "        \n",
    "    def getLeftData( data):\n",
    "        returnableDataset = pd.DataFrame(Dataset)\n",
    "        for index , row in data.iterrows():\n",
    "            returnableDataset = returnableDataset[returnableDataset['image_name'] != row['image_name'] and \n",
    "                                                 returnableDataset['image_name'] not in UsedGirl]\n",
    "            self.UsedGirls[row[\"image_name\"]] = True\n",
    "        return returnableDataset \n",
    "         #вернуть новую таблицу, состоящую из разницы Dataset/data\n",
    "        \n",
    "    def getData(self , data):\n",
    "        for index , row in data.iterrows():\n",
    "            if(row['image_name'] in DataDict):\n",
    "                self.data.append(DataFrame[{'vectors' : DataDict[row[\"image_name\"]] , 'target' : row['target']}])\n",
    "        \n",
    "        self.clf.fit(self.data['vectors'] , self.data['target'])\n",
    "        LeftData = getLeftData(self.data)\n",
    "        predictedData = self.clf.predict_log_proba(LeftData)\n",
    "        LeftData['prediction'] = pd.Series(predictedData , index = LeftData.index)\n",
    "        LeftData.sort(column='prediction' ,  ascending=False) # Отсортировать лист по <x, w> * y\n",
    "        UserArray = LeftData.head(8)#Выбрать первые 3/4 представителей от batch_size\n",
    "        UserArray.append(LeftData.sample(2)) #рандомим остальные\n",
    "        \n",
    "        return UserArray['image_name'].to_list() #Отослать юзеру эти 5 представителей (или сколько там батч у нас)\n",
    "        \n",
    "    def sendToFrontendRandomSamples(self):\n",
    "        randomSamples = Dataset.sample(batch_size)\n",
    "        return(randomSamples[\"image_name\"].tolist())\n",
    "        \n",
    "    def getScoreFromRandomSamples(self , json): #Принимаем таблицу с рандом семплами и таргетами\n",
    "        randomSamplesWithScore = JSONToDataFrame(json)\n",
    "        Rand = randomSamplesWithScore.shape['0']\n",
    "        #TP = \n",
    "    \n",
    "    def gridSearch(self):\n",
    "        grid = {'C': [0.2, 0,5, 0.75, 1, 1.25, 1.5, 2, 3]}\n",
    "        clf = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "...                          multi_class='multinomial')\n",
    "        #grid = {'C': np.power(10.0, np.arange(-5, 6))}\n",
    "        #'C':[1, 10]\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=241)\n",
    "        clf = SVC(kernel=\"linear\" , random_state = 241)\n",
    "        gs = GridSearchCV(self.clf, grid, scoring='accuracy', cv=cv)\n",
    "        gs.fit(Dataset.values[:,0:512] , self.data['target'])\n",
    "        C_best = gs.best_params_.get('C')\n",
    "        print(C_best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nik\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Nik\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Nik\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Nik\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Nik\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Nik\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Nik\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Nik\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Nik\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Nik\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Nik\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-23\n",
      "0.7871581450653984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "grid = {'C': [0.00000000000000000000001, 0.01]}\n",
    "#grid = {'random_state': [ 0, 1]}\n",
    "#grid = {'random_state': [ 0, 1]}\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=241)\n",
    "#clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "clf = SVC(kernel=\"poly\" , random_state = 241) \n",
    "#clf = xgb.XGBClassifier()\n",
    "gs = GridSearchCV(clf, grid, scoring='accuracy', cv=cv)\n",
    "gs.fit(np.array(list_vecs), np.array(list_likes))\n",
    "# Нормальный вариант - gs.fit(s , TargetData[\"target\"])\n",
    "C_best = gs.best_score_\n",
    "print(gs.best_params_.get('C'))\n",
    "#print(gs.cv_results_)\n",
    "print(C_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
